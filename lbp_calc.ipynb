{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d50961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "from skimage.feature import local_binary_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf200a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP parameters\n",
    "radius = 1\n",
    "n_points = 8 * radius\n",
    "method = 'uniform'\n",
    "\n",
    "# Landmarks indices for eyes and mouth (MediaPipe)\n",
    "LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]\n",
    "MOUTH_IDX = [61,191,13,415,291,324,14,95]  # example indices\n",
    "\n",
    "# Input dataset folder\n",
    "dataset_folders = {\n",
    "    1: \"/home/diya/Downloads/cv/datasets/banudeep/nthuddd2/drowsy\",\n",
    "    0: \"/home/diya/Downloads/cv/datasets/banudeep/nthuddd2/notdrowsy\"\n",
    "}\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = \"lbp_features_fullface.csv\"\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "def extract_roi(image, points):\n",
    "    \"\"\"Crop ROI from image using landmark points\"\"\"\n",
    "    x_min = min([p[0] for p in points])\n",
    "    x_max = max([p[0] for p in points])\n",
    "    y_min = min([p[1] for p in points])\n",
    "    y_max = max([p[1] for p in points])\n",
    "    return image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "def compute_lbp_histogram(roi):\n",
    "    \"\"\"Compute LBP and normalized histogram with fixed 59 bins\"\"\"\n",
    "    if roi.size == 0:\n",
    "        return np.zeros(59)\n",
    "    lbp = local_binary_pattern(roi, n_points, radius, method)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59), density=True)\n",
    "    return hist\n",
    "\n",
    "\n",
    "# Open CSV for writing\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # CSV header: filename + label + LBP bins\n",
    "    n_bins = 59  # for uniform LBP with 8 neighbors\n",
    "    header = [\"filename\", \"label\"] + [f\"LBP_{i}\" for i in range(n_bins*3)]  # left eye, right eye, mouth\n",
    "    writer.writerow(header)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "        for label, folder in dataset_folders.items():\n",
    "            print(f\"Processing label {label}, folder: {folder}\")\n",
    "            for filename in os.listdir(folder):\n",
    "                if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(folder, filename)\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    print(f\"Warning: {filename} could not be read. Writing NaNs...\")\n",
    "                    writer.writerow([filename, label] + [np.nan]*(n_bins*3))\n",
    "                    continue\n",
    "\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                h, w = image.shape[:2]\n",
    "\n",
    "                results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "                    # Extract ROIs\n",
    "                    left_eye_points = [(int(landmarks[i].x*w), int(landmarks[i].y*h)) for i in LEFT_EYE_IDX]\n",
    "                    right_eye_points = [(int(landmarks[i].x*w), int(landmarks[i].y*h)) for i in RIGHT_EYE_IDX]\n",
    "                    mouth_points = [(int(landmarks[i].x*w), int(landmarks[i].y*h)) for i in MOUTH_IDX]\n",
    "\n",
    "                    left_eye_roi = extract_roi(gray, left_eye_points)\n",
    "                    right_eye_roi = extract_roi(gray, right_eye_points)\n",
    "                    mouth_roi = extract_roi(gray, mouth_points)\n",
    "\n",
    "                    # Compute LBP histograms\n",
    "                    left_hist = compute_lbp_histogram(left_eye_roi)\n",
    "                    right_hist = compute_lbp_histogram(right_eye_roi)\n",
    "                    mouth_hist = compute_lbp_histogram(mouth_roi)\n",
    "\n",
    "                    # Concatenate histograms\n",
    "                    feature_vector = np.concatenate([left_hist, right_hist, mouth_hist])\n",
    "\n",
    "                    # Write filename, label, and LBP features\n",
    "                    writer.writerow([filename, label] + feature_vector.tolist())\n",
    "                    print(f\"{filename} processed. LBP features extracted.\")\n",
    "                else:\n",
    "                    writer.writerow([filename, label] + [np.nan]*(n_bins*3))\n",
    "                    print(f\"No landmarks detected for {filename}. Writing NaNs.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
