{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EAR Calculation\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye_points):\n",
    "    A = dist.euclidean(eye_points[1], eye_points[5])\n",
    "    B = dist.euclidean(eye_points[2], eye_points[4])\n",
    "    C = dist.euclidean(eye_points[0], eye_points[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# Indices for left and right eyes in MediaPipe FaceMesh\n",
    "LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "# Paths to folders containing full-face images for drowsy and not drowsy classes\n",
    "dataset_folders = {\n",
    "    1: \"\", # Path to drowsy\n",
    "    0: \"\" #Path to non drowsy\n",
    "}\n",
    "\n",
    "output_csv = \"ear_features_fullface.csv\"\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # CSV header (filename, label, avg_EAR)\n",
    "    writer.writerow([\"filename\", \"label\", \"avg_EAR\"])\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "        for label, folder in dataset_folders.items():\n",
    "            print(f\"Processing label {label}, folder: {folder}\")\n",
    "            for filename in os.listdir(folder):\n",
    "                if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(folder, filename)\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    print(f\"Warning: Unable to read image {filename}. Writing NaN...\")\n",
    "                    writer.writerow([filename, label, np.nan])\n",
    "                    continue\n",
    "\n",
    "                h, w = image.shape[:2]\n",
    "\n",
    "                results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "                    left_eye = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in LEFT_EYE_IDX]\n",
    "                    right_eye = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in RIGHT_EYE_IDX]\n",
    "\n",
    "                    left_ear = eye_aspect_ratio(left_eye)\n",
    "                    right_ear = eye_aspect_ratio(right_eye)\n",
    "                    avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                    writer.writerow([filename, label, avg_ear])\n",
    "                    print(f\"{filename} | Label: {label} | Avg EAR: {avg_ear:.3f}\")\n",
    "                else:\n",
    "                    # Instead of skipping, write NaN for missing EAR\n",
    "                    writer.writerow([filename, label, np.nan])\n",
    "                    print(f\"{filename} | Label: {label} | EAR: NaN (no landmarks)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
